walk() function can also be used for plotting
map() function
map_dbl() produces a numeric vector as the output
pmap() and pmap_dbl()

# Get the sum, of the all_tests_day list, element by element, and check its class
sum_all <- pmap_dbl(all_tests_day, sum)
class(sum_all)

# Plot all_tests_day
walk(all_tests_day, barplot)

# Plot all_tests_day with map
map(all_tests_day, barplot)

# Create all_tests list  and modify with to_day() function
all_tests <- list(visit_a, visit_b, visit_c)
all_tests_day <- map(all_tests, to_day)

# Use it on the three vectors
map(visit_a, to_day)
map(visit_b, to_day)
map(visit_c, to_day)

# Create a mapper object called to_day
to_day <- as_mapper(~ .x * 24)

# Turn visit_a into daily number of visits by using a mapper
map(visit_a, ~ .x * 24)

# Turn visit_a into daily number using an anonymous function
map(visit_a, function(x) {
  x * 24
})

# Create a threshold variable, set it to 160
threshold <- 160

# Create a mapper that tests if .x is over the defined threshold
over_threshold <- as_mapper(~ .x > threshold)

# Are all elements in every all_visits vectors over the defined threshold? 
map(all_visits, ~ every(.x, over_threshold))

# Are some elements in every all_visits vectors over the defined threshold? 
map(all_visits, ~ some(.x, over_threshold))

# Run this mapper on the all_visits_named object: group_under
group_under <-  map(all_visits_named, ~ discard(.x, threshold))

# Run this mapper on the all_visits_named object: group_over
group_over <- map(all_visits_named, ~ keep(.x, threshold))

# Create a mapper that will test if .x is over 100 
threshold <- as_mapper(~ .x > 100)

# Set the name of each subvector
day <- c("mon", "tue", "wed", "thu", "fri", "sat", "sun")
all_visits_named <- map(all_visits, ~ set_names(.x, day))

# Code a function that discard() the NULL from safe_read()
safe_read_discard <- function(url){
  safe_read(x) %>%
    discard(is.null)
}

# Map this function on the url list
res <- map(urls, safe_read_discard)

# Create a safe version of read_lines()
safe_read <- safely(read_lines)

# Keep only the elements which are equal to 404
keep(res_pasted,  res_pasted == 404)

# Paste each element of the list 
res_pasted <- map(res, paste, collapse = " ")

# Map this function on urls, pipe it into set_names()
res <- map(urls, possible_read) %>% 
set_names(urls)

# Create a possibly() version of read_lines()
possible_read <- possibly(read_lines, otherwise = 404)

# Launch purrr and httr
library(purrr)
library(httr)

# Compose a status extractor using status_code and GET functions
status_extract <- compose(status_code, GET)

# Try with "https://thinkr.fr" & "https://en.wikipedia.org"
status_extract("https://thinkr.fr")
status_extract("https://en.wikipedia.org")

# Map it on the urls vector, return a vector of numbers
map_dbl(urls, status_extract)

url_tester <- function(url_list){
  url_list %>%
    # Map a version of GET() that would otherwise return NULL 
    map( possibly(GET, otherwise = NULL) ) %>%
    # Set the names of the result
    set_names( urls ) %>%
    # Remove the NULL
    compact() %>%
    # Extract all the "status_code" elements
    map("status_code")
}

# Try this function on the urls object
url_tester(urls)

url_tester <- function(url_list){
  url_list %>%
    # Map a version of read_lines() that otherwise returns 404
    map( possibly(read_lines, otherwise = 404) ) %>%
    # Set the names of the result
    set_names( urls ) %>% 
    # paste() and collapse each element
    map(paste, collapse = " ") %>%
    # Remove the 404 
    discard( ~ .x == 404 ) %>%
    names() # Will return the names of the good ones
}

# Try this function on the urls object
url_tester(urls)
---------------------------------------------

use the %in% operator to test if one thing is inside another
Compsose() and negate() functions
Partial() function
combonitation on compose() and partial() is really powerful

Functionals: 
map_*() and map(), keep(), discard(), some(), every()

Function Operators:
safely() possibly() partial() compose() negate()


# Create a partial version of html_nodes(), with the css param set to "a"
get_a <- partial(html_nodes, css= "a")

# Create href(), a partial version of html_attr()
href <- partial(html_attr, name = "href")

# Combine href(), get_a(), and read_html() 
get_links <- compose(href, get_a, read_html)

# Map get_links() to the urls list
res <- map(urls, get_links) %>%
  set_names(urls)

# See the result
res

# Prefill html_nodes() with the css param set to h2
get_h2 <- partial(html_nodes, css = "h2")

# Combine the html_text, get_h2 and read_html functions
get_content <- compose(html_text, get_h2, read_html)

# Map get_content to the urls list
res <- map(urls, get_content) %>%
  set_names(urls)

# Print the results to the console
res

# Map the strict_code function on the urls vector
res <- map(urls, strict_code)

# Set the names of the results using the urls vector
res_named <- set_names(res, urls)

# Negate the is.na function
is_not_na <- negate(is.na)

# Run is_not_na on the results
is_not_na(res_named)

# Negate the %in% function 
`%not_in%` <- negate(`%in%`)

# Compose a status extractor 
extract_status <- compose(status_code, GET)

# Complete the function definition
strict_code <- function(url) {
  # Extract the status of the URL
  code <- extract_status(url)
  # If code is not in the acceptable range ...
  if (code %not_in% 200:203) {
    # then return NA
    return(NA)
  }
  code
}

